{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON file\n",
    "with open('./../local.settings.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Azure Cognitive Search\n",
    "search_endpoint = data[\"Values\"][\"AZURE_SEARCH_ENDPOINT\"]\n",
    "search_key = data[\"Values\"][\"AZURE_SEARCH_API_KEY\"]\n",
    "search_index_name = data[\"Values\"][\"AZURE_SEARCH_INDEX\"]\n",
    "\n",
    "# Azure OpenAI\n",
    "AOAI_key = data[\"Values\"][\"AZURE_OPENAI_API_KEY\"]\n",
    "AOAI_endpoint = data[\"Values\"][\"AZURE_OPENAI_ENDPOINT\"]\n",
    "AOAI_api_version = data[\"Values\"][\"AZURE_OPENAI_API_VERSION\"]\n",
    "embeddings_deployment = data[\"Values\"][\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"]\n",
    "chat_deployment = data[\"Values\"][\"AZURE_OPENAI_CHAT_DEPLOYMENT\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"open_checking_account\",\n",
    "                \"description\": \"Open checking accounts based on the provided parameters\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Name of the customer (i.e., muruga, parthi, etc.)\",\n",
    "                        },\n",
    "                        \"address\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Address of the customer (i.e., 3522 BC Rijnlaan, etc.)\"\n",
    "                        },\n",
    "                        \"nationality\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Nationality of the customer (i.e., Indian, Netherlands, etc.)\"\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"name\",\"address\",\"nationality\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_product_information\",\n",
    "                \"description\": \"Find information about a product based on a user question. Any information related to rabobank product should call this function. Use only if the requested information if not already available in the conversation context.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"user_question\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"User question (i.e., Can you explain various product available in Rabobank?, What is the cost of the Current Account?, etc.)\"\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"user_question\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def generate_embeddings(text):\n",
    "    \"\"\" Generate embeddings for an input string using embeddings API \"\"\"\n",
    "\n",
    "    url = f\"{AOAI_endpoint}/openai/deployments/{embeddings_deployment}/embeddings?api-version={AOAI_api_version}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": AOAI_key,\n",
    "    }\n",
    "\n",
    "    data = {\"input\": text}\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data)).json()\n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "def chat_complete(messages, tools, tool_choice='auto'):\n",
    "    \"\"\"  Return assistant chat response based on user query. Assumes existing list of messages \"\"\"\n",
    "    \n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint = AOAI_endpoint, \n",
    "        api_key=AOAI_key,  \n",
    "        api_version=\"2024-03-01-preview\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=chat_deployment,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    \n",
    "    return response\n",
    " \n",
    "def get_product_information(user_question, categories='*', top_k=1):\n",
    "    \"\"\" Vectorize user query to search Cognitive Search vector search on index_name.\"\"\"\n",
    "     \n",
    "    url = f\"{search_endpoint}/indexes/{search_index_name}/docs/search?api-version={search_api_version}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": f\"{search_key}\",\n",
    "    }\n",
    "    \n",
    "    vector = generate_embeddings(user_question)\n",
    "\n",
    "    data = {\n",
    "        \"vectors\": [\n",
    "            {\n",
    "                \"value\": vector,\n",
    "                \"fields\": \"embedding\",\n",
    "                \"k\": top_k\n",
    "            },\n",
    "        ],\n",
    "        \"select\": \"content\",\n",
    "    }\n",
    "\n",
    "    results = requests.post(url, headers=headers, data=json.dumps(data))    \n",
    "    results_json = results.json()\n",
    "    \n",
    "    # Extracting the required fields from the results JSON\n",
    "    product_data = results_json['value'][0] # hard limit to top result for now\n",
    "\n",
    "    response_data = {\n",
    "        \"content\": product_data.get('content')\n",
    "    }\n",
    "    \n",
    "    return json.dumps(response_data)\n",
    "    \n",
    "def open_checking_account(name, address, nationality):\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"name\": name,\n",
    "        \"address\": address,\n",
    "        \"nationality\": nationality\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What is the cost of the payment package in rabobank?\"}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Python HTTP trigger function processed a request.')\n",
    "#messages = json.loads(req.get_body())\n",
    "response = chat_complete(messages, tools= tools, tool_choice='auto')\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "tool_calls = response_message.tool_calls\n",
    "# Step 2: check if the model wanted to call a function\n",
    "if tool_calls:\n",
    "    # Step 3: call the function\n",
    "    # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "    available_functions = {\n",
    "        \"open_checking_account\": open_checking_account,\n",
    "        \"get_product_information\": get_product_information,\n",
    "    }  # only one function in this example, but you can have multiple\n",
    "    messages.append(response_message)  # extend conversation with assistant's reply\n",
    "    # Step 4: send the info for each function call and function response to the model\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        function_response = function_to_call(**function_args)\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "    second_response = chat_complete(messages, tools= tools, tool_choice='auto')\n",
    "    response_message = second_response.choices[0].message.content\n",
    "    \n",
    "messages.append({'role' : response_message.role, 'content' : response_message.content})\n",
    "#logging.info(json.dumps(response_message))\n",
    "\n",
    "response_object = {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
